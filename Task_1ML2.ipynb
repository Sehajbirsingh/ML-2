{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMCEt+Pz/cLXw0PBFJqfwhV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sehajbirsingh/ML-2/blob/main/Task_1ML2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K404-44Cog99",
        "outputId": "c10554ab-84ad-4033-cd3b-5afd83d388eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
        "X_train = newsgroups_train.data\n",
        "y_train = newsgroups_train.target\n",
        "X_test = newsgroups_test.data\n",
        "y_test = newsgroups_test.target"
      ],
      "metadata": {
        "id": "idKu1mMTp5xt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(classifier, X_train, X_test, y_train, y_test):\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    return accuracy, report"
      ],
      "metadata": {
        "id": "Nc74IEMdp9aF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractors = {\n",
        "    'CountVectorizer': CountVectorizer(),\n",
        "    'TF-IDF': TfidfVectorizer(),\n",
        "    'Word2Vec': None,  # Will be handled separately\n",
        "    'Doc2Vec': None   # Will be handled separately\n",
        "}\n",
        "\n",
        "algorithms = {\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=10000),\n",
        "    'LinearSVC': LinearSVC(max_iter=10000),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "EJDsPRsRqBQb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Perform benchmark analysis\n",
        "results = {}\n",
        "for feature_name, extractor in feature_extractors.items():\n",
        "    for algo_name, algorithm in algorithms.items():\n",
        "        if feature_name in ['Word2Vec', 'Doc2Vec']:\n",
        "            # Handle Word2Vec and Doc2Vec separately\n",
        "            if feature_name == 'Word2Vec':\n",
        "                # Train Word2Vec model\n",
        "                sentences = [nltk.word_tokenize(doc) for doc in X_train]\n",
        "                model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
        "                # Get document vectors by averaging word vectors\n",
        "                X_train_vec = [np.mean([model.wv[word] for word in nltk.word_tokenize(doc) if word in model.wv] or [np.zeros(100)], axis=0) for doc in X_train]\n",
        "                X_test_vec = [np.mean([model.wv[word] for word in nltk.word_tokenize(doc) if word in model.wv] or [np.zeros(100)], axis=0) for doc in X_test]\n",
        "\n",
        "                # Scale feature vectors to non-negative values using MinMaxScaler for MultinomialNB compatibility\n",
        "                if algo_name == 'MultinomialNB':\n",
        "                    scaler = MinMaxScaler()\n",
        "                    X_train_vec = scaler.fit_transform(X_train_vec)\n",
        "                    X_test_vec = scaler.transform(X_test_vec)\n",
        "\n",
        "            else:  # Doc2Vec\n",
        "                # Train Doc2Vec model\n",
        "                documents = [TaggedDocument(nltk.word_tokenize(doc), [i]) for i, doc in enumerate(X_train)]\n",
        "                model = Doc2Vec(documents, vector_size=100, window=5, min_count=5, workers=4)\n",
        "                # Get document vectors\n",
        "                X_train_vec = [model.infer_vector(nltk.word_tokenize(doc)) for doc in X_train]\n",
        "                X_test_vec = [model.infer_vector(nltk.word_tokenize(doc)) for doc in X_test]\n",
        "\n",
        "                # Scale feature vectors to non-negative values using MinMaxScaler for MultinomialNB compatibility\n",
        "                if algo_name == 'MultinomialNB':\n",
        "                    scaler = MinMaxScaler()\n",
        "                    X_train_vec = scaler.fit_transform(X_train_vec)\n",
        "                    X_test_vec = scaler.transform(X_test_vec)\n",
        "\n",
        "            accuracy, report = train_and_evaluate(algorithm, X_train_vec, X_test_vec, y_train, y_test)\n",
        "        else:\n",
        "            # Use CountVectorizer or TF-IDF\n",
        "            X_train_vec = extractor.fit_transform(X_train)\n",
        "            X_test_vec = extractor.transform(X_test)\n",
        "            accuracy, report = train_and_evaluate(algorithm, X_train_vec, X_test_vec, y_train, y_test)\n",
        "\n",
        "        results[(feature_name, algo_name)] = {\n",
        "            'accuracy': accuracy,\n",
        "            'report': report\n",
        "        }\n",
        "\n",
        "# Print the results\n",
        "for (feature_name, algo_name), result in results.items():\n",
        "    print(f\"Feature Extractor: {feature_name}, Algorithm: {algo_name}\")\n",
        "    print(f\"Accuracy: {result['accuracy']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H1MQHPXqHGb",
        "outputId": "59be08db-fb5d-4564-a8d4-747e69f99c20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Extractor: CountVectorizer, Algorithm: MultinomialNB\n",
            "Accuracy: 0.5431492299522039\n",
            "Feature Extractor: CountVectorizer, Algorithm: LogisticRegression\n",
            "Accuracy: 0.596388741370154\n",
            "Feature Extractor: CountVectorizer, Algorithm: LinearSVC\n",
            "Accuracy: 0.5720924057355284\n",
            "Feature Extractor: CountVectorizer, Algorithm: DecisionTreeClassifier\n",
            "Accuracy: 0.4212692511949018\n",
            "Feature Extractor: TF-IDF, Algorithm: MultinomialNB\n",
            "Accuracy: 0.6062134891131173\n",
            "Feature Extractor: TF-IDF, Algorithm: LogisticRegression\n",
            "Accuracy: 0.6744556558682953\n",
            "Feature Extractor: TF-IDF, Algorithm: LinearSVC\n",
            "Accuracy: 0.6919808815719597\n",
            "Feature Extractor: TF-IDF, Algorithm: DecisionTreeClassifier\n",
            "Accuracy: 0.4038767923526288\n",
            "Feature Extractor: Word2Vec, Algorithm: MultinomialNB\n",
            "Accuracy: 0.19928305894848647\n",
            "Feature Extractor: Word2Vec, Algorithm: LogisticRegression\n",
            "Accuracy: 0.34877854487519916\n",
            "Feature Extractor: Word2Vec, Algorithm: LinearSVC\n",
            "Accuracy: 0.34891131173659057\n",
            "Feature Extractor: Word2Vec, Algorithm: DecisionTreeClassifier\n",
            "Accuracy: 0.17445565586829528\n",
            "Feature Extractor: Doc2Vec, Algorithm: MultinomialNB\n",
            "Accuracy: 0.22464152947424323\n",
            "Feature Extractor: Doc2Vec, Algorithm: LogisticRegression\n",
            "Accuracy: 0.4796866702071163\n",
            "Feature Extractor: Doc2Vec, Algorithm: LinearSVC\n",
            "Accuracy: 0.4451672862453532\n",
            "Feature Extractor: Doc2Vec, Algorithm: DecisionTreeClassifier\n",
            "Accuracy: 0.18428040361125864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tcEMjib9ltg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}